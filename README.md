# Raw Data Loader

Um pipeline de ELT (Extract, Load, Transform) simples e robusto, projetado para extrair dados brutos de forma incremental de um banco de dados SQL (SQL Server) e carreg√°-los no Google Cloud Storage (GCS) em formato Parquet particionado.

O projeto √© constru√≠do para rodar como um job containerizado (ex: no Cloud Run Jobs) e √© totalmente configur√°vel via argumentos de linha de comando e vari√°veis de ambiente, tornando-o facilmente reutiliz√°vel para diferentes tabelas.

## ‚ú® Principais Funcionalidades

-   **Extra√ß√£o Incremental:** Utiliza uma coluna de cursor (ex: `dt_atualizacao`) para buscar de forma eficiente apenas os dados novos ou atualizados.
-   **Tratamento de *Schema Drift*:** Lida de forma resiliente com mudan√ßas no schema da origem, ignorando novas colunas e preenchendo colunas deletadas com nulos, prevenindo falhas no pipeline.
-   **Sa√≠da em Parquet Particionado:** Carrega os dados no GCS utilizando particionamento no estilo Hive (`year=.../month=.../day=...`) e o eficiente formato Parquet, otimizado para analytics.
-   **Containerizado e Nativo para Nuvem:** Constru√≠do com Docker e projetado para execu√ß√£o *serverless* em plataformas como o Cloud Run Jobs.
-   **Configura√ß√£o Din√¢mica:** Adapte facilmente o pipeline para diferentes tabelas de origem alterando os argumentos de linha de comando, sem necessidade de mudar o c√≥digo.


## üíª Stack de Tecnologia

-   **Linguagem:** Python 3.13
-   **Gerenciador de Pacotes:** `uv`
-   **Processamento de Dados:** Pandas, PyArrow
-   **Conectividade:** SQLAlchemy, pyodbc
-   **Containeriza√ß√£o:** Docker
-   **Cloud:** Google Cloud (Cloud Run, GCS, Secret Manager, Cloud Build, Artifact Registry)


## üèóÔ∏è Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ app/                # C√≥digo fonte da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ config/         # M√≥dulos de configura√ß√£o (vari√°veis de ambiente, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ controller/     # Controladores para extra√ß√£o, transforma√ß√£o e carga
‚îÇ   ‚îú‚îÄ‚îÄ core/           # L√≥gica de neg√≥cios principal (conex√£o com DB, GCP)
‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Fun√ß√µes utilit√°rias (logger, schema, etc.)
‚îú‚îÄ‚îÄ secret/             # Arquivos de segredo e configura√ß√£o (n√£o versionados)
‚îú‚îÄ‚îÄ .dockerignore       # Arquivos a serem ignorados pelo Docker
‚îú‚îÄ‚îÄ .gitignore          # Arquivos a serem ignorados pelo Git
‚îú‚îÄ‚îÄ docker-compose.yml  # Configura√ß√£o do Docker Compose para ambiente local
‚îú‚îÄ‚îÄ Dockerfile          # Dockerfile para a imagem de produ√ß√£o
‚îú‚îÄ‚îÄ Dockerfile.dev      # Dockerfile para o ambiente de desenvolvimento
‚îú‚îÄ‚îÄ pyproject.toml      # Arquivo de configura√ß√£o do projeto Python e depend√™ncias
‚îú‚îÄ‚îÄ README.md           # Este arquivo
‚îî‚îÄ‚îÄ uv.lock             # Arquivo de lock do gerenciador de pacotes uv
```

## ‚öôÔ∏è Configura√ß√£o

O pipeline √© configurado principalmente por um arquivo de manifesto (`manifest.json`) e por vari√°veis de ambiente.

### Arquivo de Manifesto (`manifest.json`)

O arquivo de manifesto √© um arquivo JSON que define a lista de jobs a serem executados. Cada objeto na lista representa um job e cont√©m os seguintes par√¢metros:

| Par√¢metro | Obrigat√≥rio | Padr√£o | Descri√ß√£o |
| :--- | :--- | :--- | :--- |
| `schema_name` | **Sim** | - | Nome do schema do banco de dados a ser processado. |
| `table_name` | **Sim** | - | Nome da tabela a ser processada. |
| `cursor_column` | **Sim** | - | Nome da coluna de cursor para a carga incremental. |
| `chunk_size` | N√£o | `1000000` | N√∫mero de linhas a serem extra√≠das em cada lote (chunk). |

O job a ser executado √© selecionado pela vari√°vel de ambiente `CLOUD_RUN_TASK_INDEX`.

### Vari√°veis de Ambiente

Estas vari√°veis configuram o ambiente de execu√ß√£o e as conex√µes com os servi√ßos.

| Vari√°vel | Descri√ß√£o |
| :--- | :--- |
| `DB_USER` | Usu√°rio de acesso ao banco de dados. |
| `DB_PASSWORD` | Senha de acesso ao banco de dados (em produ√ß√£o, usar Secret Manager).|
| `DB_HOST` | Hostname ou endere√ßo IP do servidor do banco de dados. |
| `DB_PORT` | Porta do servidor do banco de dados. |
| `DB_NAME` | Nome do banco de dados. |
| `GCP_PROJECT_ID` | ID do projeto no Google Cloud. |
| `GCS_BUCKET_NAME`| Nome do bucket no Google Cloud Storage para onde os dados ser√£o enviados.|
| `EXECUTION_TS` | Timestamp da execu√ß√£o (usado para particionamento). |
| `CLOUD_RUN_TASK_INDEX` | √çndice do job a ser executado a partir do arquivo de manifesto. |


## üöÄ Deploy em Produ√ß√£o (Google Cloud Run Jobs)

O deploy em produ√ß√£o √© feito construindo uma imagem Docker e criando um Job no Google Cloud Run, que pode ser executado manualmente ou orquestrado por um scheduler como o Cloud Composer (Airflow).

### Passo 1: Gerenciar Segredos ü§´

Guarde todas as senhas e chaves de acesso no **Google Secret Manager**. Voc√™ pode criar um segredo a partir de um arquivo `.env` local.

```bash
# Crie um arquivo .env com as vari√°veis de ambiente de produ√ß√£o
# Exemplo de conte√∫do do .env:
# DB_USER=...
# DB_PASSWORD=...
# ...

# Crie o segredo no Secret Manager
gcloud secrets create NOME_DO_SEGREDO --data-file=./secret/.env
```

### Passo 2: Construir e Enviar a Imagem

Use o Google Cloud Build para construir a imagem Docker a partir do `Dockerfile` e envi√°-la para o Google Artifact Registry.

1.  **Ative as APIs necess√°rias:**
    -   Cloud Build API
    -   Artifact Registry API

2.  **Crie um reposit√≥rio no Artifact Registry:**
    ```bash
    gcloud artifacts repositories create NOME_DO_REPOSITORIO \
        --repository-format=docker \
        --location=SUA_REGIAO
    ```

3.  **Envie a imagem para o Cloud Build:**
    ```bash
    gcloud builds submit --tag SUA_REGIAO-docker.pkg.dev/SEU_PROJETO/NOME_DO_REPOSITORIO/NOME_DA_IMAGEM:latest
    ```

### Passo 3: Criar/Atualizar o Cloud Run Job

Crie um Job no Cloud Run para executar o pipeline.

```bash
gcloud run jobs deploy NOME_DO_JOB \
    --image=SUA_REGIAO-docker.pkg.dev/SEU_PROJETO/NOME_DO_REPOSITORIO/NOME_DA_IMAGEM:latest \
    --region=SUA_REGIAO \
    --service-account=SUA_CONTA_DE_SERVICO \
    --set-secrets=VARIAVEL_DE_AMBIENTE=NOME_DO_SEGREDO:latest \
    # Adicione outras configura√ß√µes como mem√≥ria, CPU, etc.
```

**Importante:**
- Substitua `SUA_REGIAO`, `SEU_PROJETO`, `NOME_DO_REPOSITORIO`, `NOME_DA_IMAGEM`, `NOME_DO_JOB`, `SUA_CONTA_DE_SERVICO`, `VARIAVEL_DE_AMBIENTE` e `NOME_DO_SEGREDO` pelos seus valores.
- A `VARIAVEL_DE_AMBIENTE` no comando `--update-secrets` deve ser o nome da vari√°vel de ambiente que o seu c√≥digo espera (ex: `DB_PASSWORD`).

### Passo 4: Executar o Job

Execute o Job manualmente ou orquestre-o com o Cloud Composer (Airflow).

**Execu√ß√£o Manual:**

Para executar um job espec√≠fico do manifesto, configure a vari√°vel de ambiente `CLOUD_RUN_TASK_INDEX`.

```bash
gcloud run jobs execute NOME_DO_JOB \
    --region=SUA_REGIAO \
    --update-env-vars=CLOUD_RUN_TASK_INDEX=0 # Execute o primeiro job do manifesto
```

**Orquestra√ß√£o com Airflow:**

Use o `CloudRunExecuteJobOperator` para executar o job a partir de um DAG do Airflow.

```python
from airflow.providers.google.cloud.operators.cloud_run import CloudRunExecuteJobOperator

run_task = CloudRunExecuteJobOperator(
    task_id="run_etl_for_my_table",
    project_id="SEU_PROJETO",
    region="SUA_REGIAO",
    job_name="NOME_DO_JOB",
    overrides={
        "container_overrides": [
            {
                "name": "NOME_DO_CONTAINER", # Geralmente 'app' ou 'default'
                "env": [
                    {
                        "name": "CLOUD_RUN_TASK_INDEX",
                        "value": "0"
                    }
                ]
            }
        ]
    },
)
```

## üîÅ CI/CD (GitHub Actions)

O reposit√≥rio cont√©m um workflow em `.github/workflows/deploy.yml` que:

- Faz build e push da imagem para o Artifact Registry.
- Faz o deploy do Cloud Run Job com `gcloud run jobs deploy` (cria ou atualiza).
- Registra a especifica√ß√£o final do Job e a imagem implantada no log do workflow.
- Usa controle de concorr√™ncia para evitar deploys sobrepostos.

Dispare o workflow em pushes no branch `main` que alterem `app/**`, `Dockerfile`, `pyproject.toml`, `uv.lock` ou o pr√≥prio workflow.

Secrets necess√°rios no reposit√≥rio:

- `GOOGLE_CREDENTIALS` (JSON do service account com permiss√£o em Artifact Registry e Cloud Run)
- `GCP_REGION`, `GCP_PROJECT_ID`, `GCP_ARTIFACT_REPO_NAME`, `GCP_IMAGE_NAME`, `GCP_IMAGE_TAG_NAME`
- `GCP_SERVICE_ACCOUNT`, `GCP_NETWORK`, `GCP_SUBNETWORK`

## üß™ Testes e Qualidade

- Testes unit√°rios: `uv run pytest -q`
- Type-check: `uv run pyright`
- Lint/format: `uv run ruff check` e `uv run ruff format`

## üß≠ Execu√ß√£o Local (Docker Compose)

Para rodar localmente com Docker Compose:

1. Crie `secret/.env` com as vari√°veis obrigat√≥rias (consulte `app/config/env.py`).
2. Garanta que o arquivo `secret/key-file.json` (ADC) exista localmente.
3. Execute `docker compose up --build`.

O compose injeta `GOOGLE_APPLICATION_CREDENTIALS` e define um `EXECUTION_TS` default. O arquivo de manifesto √© lido do GCS em `mssql/manifest.json`.

## üìå Notas de Produ√ß√£o

- SQL incremental (pyodbc): a query usa marcadores posicionais `?` e `pandas.read_sql` recebe `params=(last_cursor,)`. Isso √© essencial para evitar o erro `The SQL contains 0 parameter markers, but 1 parameters were supplied`.
- Particionamento no GCS: os arquivos s√£o gravados em `mssql/tables/<table>/ingestion/year=YYYY/month=MM/day=DD/hour=HH/<timestamp>_<chunk>.parquet`.
- Timestamps: se `EXECUTION_TS` for inv√°lido/missing, o loader usa `datetime.now(timezone.utc)` e loga um aviso/erro apropriado.
- Imagem Docker: use `.dockerignore` para excluir `.venv/`, caches e `secret/` do contexto de build. Para imagens menores, considere multi-stage build (builder com `uv` e runtime em `python:3.13-slim`) caso necess√°rio.
